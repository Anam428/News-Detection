{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dependencies"
      ],
      "metadata": {
        "id": "B0QGRwBP8og2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo5YtN3N8nzx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "df_fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "df_real = pd.read_csv(\"/content/True.csv\")\n",
        "\n",
        "# Add labels: Fake = 1, Real = 0\n",
        "df_fake[\"label\"] = 1\n",
        "df_real[\"label\"] = 0\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([df_fake, df_real], axis=0)\n",
        "\n",
        "# Shuffle dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save merged file\n",
        "df.to_csv(\"/content/merged_news.csv\", index=False)\n",
        "print(\"Merged dataset saved as 'merged_news.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAReTh1P-Fm4",
        "outputId": "ed414088-97e8-4352-9dc7-4ef0c60a2940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as 'merged_news.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fake News dataset\n",
        "df_fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "df_fake[\"label\"] = 1  # Assign label 1 for Fake news\n",
        "\n",
        "# Load True News dataset\n",
        "df_True = pd.read_csv(\"/content/True.csv\")\n",
        "df_True[\"label\"] = 0  # Assign label 0 for Real news\n",
        "\n",
        "# Merge both datasets\n",
        "df = pd.concat([df_fake, df_True], ignore_index=True)\n",
        "\n",
        "# Display dataset info\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OWyeJaHQ-k5g",
        "outputId": "2d371189-27ab-48f8-8a4b-80328b16b11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44898 entries, 0 to 44897\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    44898 non-null  object\n",
            " 1   text     44898 non-null  object\n",
            " 2   subject  44898 non-null  object\n",
            " 3   date     44898 non-null  object\n",
            " 4   label    44898 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.7+ MB\n",
            "None\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "2  On Friday, it was revealed that former Milwauk...    News   \n",
            "3  On Christmas day, Donald Trump announced that ...    News   \n",
            "4  Pope Francis used his annual Christmas Day mes...    News   \n",
            "\n",
            "                date  label  \n",
            "0  December 31, 2017      1  \n",
            "1  December 31, 2017      1  \n",
            "2  December 30, 2017      1  \n",
            "3  December 29, 2017      1  \n",
            "4  December 25, 2017      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Preprocess Data"
      ],
      "metadata": {
        "id": "dCFhx3HqARHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "df_fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "df_real = pd.read_csv(\"/content/True.csv\")\n",
        "\n",
        "# Add labels: Fake = 1, Real = 0\n",
        "df_fake[\"label\"] = 1\n",
        "df_real[\"label\"] = 0\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([df_fake, df_real], axis=0)\n",
        "\n",
        "# Shuffle dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save merged file\n",
        "df.to_csv(\"/content/merged_news.csv\", index=False)\n",
        "print(\"Merged dataset saved as 'merged_news.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpkJTK6_AU5F",
        "outputId": "b73e33f9-bc15-46c1-f251-52dae872f6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as 'merged_news.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/merged_news.csv\")\n"
      ],
      "metadata": {
        "id": "naJgUIPgA6O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data"
      ],
      "metadata": {
        "id": "gjkpbk6GBGpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load merged dataset (Fake + Real)\n",
        "df = pd.read_csv(\"/content/merged_news.csv\")  # Change this to your merged dataset path\n",
        "\n",
        "# Keep only relevant columns (assuming 'text' and 'label' exist)\n",
        "df = df[['text', 'label']].dropna()\n",
        "\n",
        "# Check class distribution\n",
        "print(df['label'].value_counts())  # Ensure Fake (1) and Real (0) are balanced\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoYqu1JhAAOE",
        "outputId": "424d559d-8d40-48bd-8a00-bf476c03c152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    23481\n",
            "0    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Text Data"
      ],
      "metadata": {
        "id": "JUrTc6BEBOD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in brackets\n",
        "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", '', text)  # Remove URLs\n",
        "    text = re.sub(r\"<.*?>+\", '', text)  # Remove HTML tags\n",
        "    text = re.sub(r\"[^\\w\\s]\", '', text)  # Remove punctuation\n",
        "    text = re.sub(r\"\\d+\", '', text)  # Remove numbers\n",
        "    text = text.strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "df['text'] = df['text'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "D1VsBFP3BSkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "aSbhe7ioBYZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nT-GOvM_BdBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Text to Numerical Form (TF-IDF)\n"
      ],
      "metadata": {
        "id": "RO_lCA-JBgTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "yS_P08ruBlS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train ML Model\n"
      ],
      "metadata": {
        "id": "GixxVlwjBsgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu_RzEAABvTs",
        "outputId": "0a5e5b32-8233-4c12-e52c-8445da2b0c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9863\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      4270\n",
            "           1       0.99      0.98      0.99      4710\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Function"
      ],
      "metadata": {
        "id": "hL6LvKycB-Fu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VknfbPJQCB5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/merged_news.csv\")  # Change if needed\n",
        "\n",
        "# Ensure correct columns\n",
        "if 'text' not in df.columns or 'label' not in df.columns:\n",
        "    print(\"Dataset must have 'text' and 'label' columns!\")\n",
        "else:\n",
        "    # Prepare data\n",
        "    X = df['text']\n",
        "    y = df['label']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Convert text to TF-IDF features\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train a Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Save model and vectorizer\n",
        "    joblib.dump(model, \"/content/fake_news_model.pkl\")\n",
        "    joblib.dump(vectorizer, \"/content/tfidf_vectorizer.pkl\")\n",
        "\n",
        "    print(\"Model and vectorizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tvhhZ8HDQUp",
        "outputId": "a501d88f-d13f-4984-9199-752d6a1634e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and vectorizer\n",
        "model = joblib.load(\"/content/fake_news_model.pkl\")  # Correct model file\n",
        "vectorizer = joblib.load(\"/content/tfidf_vectorizer.pkl\")  # Correct vectorizer file\n",
        "\n",
        "def predict_news(text):\n",
        "    \"\"\"\n",
        "    Predicts if a given news article is fake or real.\n",
        "\n",
        "    Args:\n",
        "        text (str): The news article text.\n",
        "\n",
        "    Returns:\n",
        "        str: \"Fake News\" or \"Real News\"\n",
        "    \"\"\"\n",
        "    text_tfidf = vectorizer.transform([text])\n",
        "    prediction = model.predict(text_tfidf)[0]\n",
        "    return \"Fake News\" if prediction == 1 else \"Real News\"\n",
        "\n",
        "# Example usage\n",
        "news_text = \"FBI Russia probe helped by Australian diplomat tip-off: NYT\"\n",
        "print(predict_news(news_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66xKGfJ-DYZS",
        "outputId": "3ed338fc-36e1-42b4-b2c4-f92c7d972bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3XpsVSpa6nG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}